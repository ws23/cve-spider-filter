import scrapy, logging, datetime
from cve.items import CveItem
from cve.middlewares import SeleniumRequest


class CveSpider(scrapy.Spider):

    name = 'cve'

    today = datetime.date.today()
    parse_day = 1                   # 可設定要爬取的 CVE 編號來源是要幾天的資料

    allowed_domains = ['cassandra.cerias.purdue.edu', 'nvd.nist.gov']
    start_urls = ['https://cassandra.cerias.purdue.edu/CVE_changes/today.html']
    
    # 取得 CVE 編號新增/更新清單的 URL
    for i in range(1, parse_day, 1):
        dt = today - datetime.timedelta(days=(i+1))
        start_urls.append('https://cassandra.cerias.purdue.edu/CVE_changes/CVE.' + dt.strftime('%Y.%m.%d') + '.html')
    
    
    def start_requests(self):
        for url in self.start_urls:
            yield scrapy.Request(url=url, callback=self.cve_parse,)
            
    # 爬取新增/更新的 CVE 編號
    def cve_parse(self, response):
        res = response.xpath("//a")
        for ids in res:
            id = ids.xpath("./text()").extract_first()
            cveid = "CVE-" + id
            url = "https://nvd.nist.gov/vuln/detail/{}".format(cveid)
            yield SeleniumRequest(url=url, callback=self.search, meta={'id':cveid})
        
    # 爬取 CVE detail (from nvd)
    def search(self, response):
        sec_cve_id = response.meta['id']
        
        description = response.xpath("/html/body/div[2]/div[2]/div[2]/table/tbody/tr/td/div/div[1]/p[1]/text()").extract_first()
        cvss = response.xpath("/html/body/div[2]/div[2]/div[2]/table/tbody/tr/td/div/div[1]/div[2]/div[2]/div[1]/div[2]/span/span/a/text()").extract_first()
        publish = response.xpath("/html/body/div[2]/div[2]/div[2]/table/tbody/tr/td/div/div[2]/div/span[1]/text()").extract_first()
        modified = response.xpath("/html/body/div[2]/div[2]/div[2]/table/tbody/tr/td/div/div[2]/div/span[2]/text()").extract_first()
        
        # 最後修改日期與發佈日期相同視作新條目
        if publish == modified:
            is_new = "T"
        else:
            is_new = "F"

        # 以 YYYY/MM/DD 格式儲存日期
        published = publish.split('/')[2] + "/" + publish.split('/')[0] + "/" + publish.split('/')[1]
        if cvss == "N/A":
            severity = ""
            score = ""
        else:
            severity = cvss.split(' ')[1]
            score = cvss.split(' ')[0]
        
        
        item = CveItem()
        item["cve_id"] = sec_cve_id
        item["cve_desc"] = description
        item["cve_score"] = score
        item["cve_severity"] = severity
        item["cve_published_date"] = published
        item["cve_is_new"] = is_new

        yield item
